%EXAMPLE_CON_WU
% Script example pipeline CON WU

clear variables %#ok<*NASGU>


%% Load BrainAtlas
im_ba = ImporterBrainAtlasXLS( ...
    'FILE', [which('aal94_atlas.xlsx')], ...
    'WAITBAR', true ...
    );

ba = im_ba.get('BA');

%% load Nifty images
%%group1
im_gr1_WM_GM = ImporterGroupSubjNIfTI('DIRECTORY', [fileparts(which('AD_PositiveAmyloid.vois.xlsx')) filesep 'AD_PositiveAmyloid'], ...
    'NIFTI_TYPE', {'WM','GM'},...
    'WAITBAR', true);
gr1_WM_GM = im_gr1_WM_GM.get('GR');

im_gr1_PET = ImporterGroupSubjNIfTI('DIRECTORY', [fileparts(which('AD_PositiveAmyloid.vois.xlsx')) filesep 'AD_PositiveAmyloid'], ...
    'NIFTI_TYPE', {'wroriented_raw_pet'},...
    'WAITBAR', true);
gr1_PET = im_gr1_PET.get('GR');

%%group2
im_gr2_WM_GM = ImporterGroupSubjNIfTI('DIRECTORY',[fileparts(which('Healthy_NegativeAmyloid.vois.xlsx')) filesep 'Healthy_NegativeAmyloid'], ...
    'NIFTI_TYPE', {'WM','GM'},...
    'WAITBAR', true);
gr2_WM_GM = im_gr2_WM_GM.get('GR');

im_gr2_PET = ImporterGroupSubjNIfTI('DIRECTORY', [fileparts(which('Healthy_NegativeAmyloid.vois.xlsx')) filesep 'Healthy_NegativeAmyloid'], ...
    'NIFTI_TYPE', {'wroriented_raw_pet'},...
    'WAITBAR', true);
gr2_PET = im_gr2_PET.get('GR');

%%group3
im_gr3_WM_GM = ImporterGroupSubjNIfTI('DIRECTORY', [fileparts(which('MCI_PositiveAmyloid.vois.xlsx')) filesep 'MCI_PositiveAmyloid'], ...
    'NIFTI_TYPE', {'WM','GM'},...
    'WAITBAR', true);
gr3_WM_GM = im_gr3_WM_GM.get('GR');

im_gr3_PET = ImporterGroupSubjNIfTI('DIRECTORY', [fileparts(which('MCI_PositiveAmyloid.vois.xlsx')) filesep 'MCI_PositiveAmyloid'], ...
    'NIFTI_TYPE', {'wroriented_raw_pet'},...
    'WAITBAR', true);
gr3_PET = im_gr3_PET.get('GR');
%% ROI constructor

path_dict = IndexedDictionary(...
    'IT_CLASS', 'FILE_PATH', ...
    'IT_LIST', {FILE_PATH('PATH',which('upsampled_AAL2.nii')),FILE_PATH('PATH', which('upsampled_TD.nii'))} ...
    );

gr1 = SUVRConstructor('GR_PET',gr1_PET, ...
    'GR_T1',gr1_WM_GM, ...
    'BA', ba,...
    'ATLAS_PATH_DICT' ,path_dict, ...
    'REF_REGION_LIST',{[9100,9110,9120,9130,9140,9150,9160,9170], 7}, ...
    'ATLAS_KIND', {'AAL2','TD'});
SUVR_gr1 = gr1.get('GR');

gr2 = SUVRConstructor('GR_PET',gr2_PET, ...
    'GR_T1',gr2_WM_GM, ...
    'BA', ba,...
    'ATLAS_PATH_DICT' ,path_dict, ...
    'REF_REGION_LIST',{[9100,9110,9120,9130,9140,9150,9160,9170], 7}, ...
    'ATLAS_KIND', {'AAL2','TD'});
SUVR_gr_healthy = gr2.get('GR');

gr3 = SUVRConstructor('GR_PET',gr3_PET, ...
    'GR_T1',gr3_WM_GM, ...
    'BA', ba,...
    'ATLAS_PATH_DICT' ,path_dict, ...
    'REF_REGION_LIST',{[9100,9110,9120,9130,9140,9150,9160,9170], 7}, ...
    'ATLAS_KIND', {'AAL2','TD'});
SUVR_gr3 = gr3.get('GR');


%% Load Groups of SubjectCON Deviation based
im_gr1 = IndividualDeviationConConstructor( ...
    'GR_SUVR', SUVR_gr1,...
    'GR_SUVR_REF', SUVR_gr_healthy);

Con_gr1 = im_gr1.get('GR'); % AD vs. CN

im_gr2 = IndividualDeviationConConstructor( ...
    'GR_SUVR', SUVR_gr_healthy,...
    'GR_SUVR_REF', SUVR_gr_healthy);

Con_gr2 = im_gr2.get('GR'); % CN


im_gr3 = IndividualDeviationConConstructor( ...
    'GR_SUVR', SUVR_gr3,...
    'GR_SUVR_REF', SUVR_gr_healthy);

Con_gr3 = im_gr3.get('GR'); % MCI vs. CN

%% NN DATASET

it_list1 = cellfun(@(x) NNDataPoint_CON_CLA( ...
    'ID', x.get('ID'), ...
    'SUB', x, ...
    'TARGET_CLASS', {gr1_PET.get('ID')}), ...
    Con_gr1.get('SUB_DICT').get('IT_LIST'), ...
    'UniformOutput', false);

% Get the subject dictionary and extract the list of subjects
sub_dict1 = gr1_WM_GM.get('SUB_DICT');
sub_list1 = sub_dict1.get('IT_LIST'); % Get all subjects as a cell array
[~, group_folder_name1] = fileparts(im_gr1_PET.get('DIRECTORY'));
% Use cellfun to create NNDataPoint_VOIs for each subject
it_list_voi1 = cellfun(@(sub) NNDataPoint_VOIs( ...
    'ID', sub.get('ID'), ...
    'VOI_DICT', IndexedDictionary( ...
        'ID', 'subject_idict', ...
        'IT_CLASS', 'SubjectNIfTI', ...
        'IT_KEY', IndexedDictionary.getPropDefault(IndexedDictionary.IT_KEY), ...
        'IT_LIST', sub.get('VOI_DICT').get('IT_LIST') ...
        ), ...
    'TARGET_CLASS', {group_folder_name1} ...
    ), sub_list1, 'UniformOutput', false);


it_list2 = cellfun(@(x) NNDataPoint_CON_CLA( ...
    'ID', x.get('ID'), ...
    'SUB', x, ...
    'TARGET_CLASS', {gr2_PET.get('ID')}), ...
    Con_gr2.get('SUB_DICT').get('IT_LIST'), ...
    'UniformOutput', false);
% Get the subject dictionary and extract the list of subjects
sub_dict2 = gr2_WM_GM.get('SUB_DICT');
sub_list2 = sub_dict2.get('IT_LIST'); % Get all subjects as a cell array
[~, group_folder_name2] = fileparts(im_gr2_PET.get('DIRECTORY'));
% Use cellfun to create NNDataPoint_VOIs for each subject
it_list_voi2 = cellfun(@(sub) NNDataPoint_VOIs( ...
    'ID', sub.get('ID'), ...
    'VOI_DICT', IndexedDictionary( ...
        'ID', 'subject_idict', ...
        'IT_CLASS', 'SubjectNIfTI', ...
        'IT_KEY', IndexedDictionary.getPropDefault(IndexedDictionary.IT_KEY), ...
        'IT_LIST', sub.get('VOI_DICT').get('IT_LIST') ...
        ), ...
    'TARGET_CLASS', {group_folder_name2} ...
    ), sub_list2, 'UniformOutput', false);

it_list3 = cellfun(@(x) NNDataPoint_CON_CLA( ...
    'ID', x.get('ID'), ...
    'SUB', x, ...
    'TARGET_CLASS', {gr3_PET.get('ID')}), ...
    Con_gr3.get('SUB_DICT').get('IT_LIST'), ...
    'UniformOutput', false);
% Get the subject dictionary and extract the list of subjects
sub_dict3 = gr3_WM_GM.get('SUB_DICT');
sub_list3 = sub_dict3.get('IT_LIST'); % Get all subjects as a cell array
[~, group_folder_name3] = fileparts(im_gr3_PET.get('DIRECTORY'));
% Use cellfun to create NNDataPoint_VOIs for each subject
it_list_voi3 = cellfun(@(sub) NNDataPoint_VOIs( ...
    'ID', sub.get('ID'), ...
    'VOI_DICT', IndexedDictionary( ...
        'ID', 'subject_idict', ...
        'IT_CLASS', 'SubjectNIfTI', ...
        'IT_KEY', IndexedDictionary.getPropDefault(IndexedDictionary.IT_KEY), ...
        'IT_LIST', sub.get('VOI_DICT').get('IT_LIST') ...
        ), ...
    'TARGET_CLASS', {group_folder_name3} ...
    ), sub_list3, 'UniformOutput', false);


% create NNDataPoint_CON_CLA DICT items
dp_list1 = IndexedDictionary(...
        'IT_CLASS', 'NNDataPoint_CON_CLA', ...
        'IT_LIST', it_list1 ...
        );

dp_list2 = IndexedDictionary(...
        'IT_CLASS', 'NNDataPoint_CON_CLA', ...
        'IT_LIST', it_list2 ...
        );

dp_list3 = IndexedDictionary(...
        'IT_CLASS', 'NNDataPoint_CON_CLA', ...
        'IT_LIST', it_list3 ...
        );

dp_list_voi1 = IndexedDictionary(...
        'IT_CLASS', 'NNDataPoint_VOIs', ...
        'IT_LIST', it_list_voi1 ...
        );

dp_list_voi2 = IndexedDictionary(...
        'IT_CLASS', 'NNDataPoint_VOIs', ...
        'IT_LIST', it_list_voi2 ...
        );

dp_list_voi3 = IndexedDictionary(...
        'IT_CLASS', 'NNDataPoint_VOIs', ...
        'IT_LIST', it_list_voi3 ...
        );


d1 = NNDataset( ...
    'DP_CLASS', 'NNDataPoint_Graph_CLA', ...
    'DP_DICT', dp_list1 ...
    );
d1_vois = NNDataset( ...
    'DP_CLASS', 'NNDataPoint_VOIs', ...
    'DP_DICT', dp_list_voi1 ...
    );

d2 = NNDataset( ...
    'DP_CLASS', 'NNDataPoint_Graph_CLA', ...
    'DP_DICT', dp_list2 ...
    );
d2_vois = NNDataset( ...
    'DP_CLASS', 'NNDataPoint_VOIs', ...
    'DP_DICT', dp_list_voi2 ...
    );

d3 = NNDataset( ...
    'DP_CLASS', 'NNDataPoint_Graph_CLA', ...
    'DP_DICT', dp_list3 ...
    );
d3_vois = NNDataset( ...
    'DP_CLASS', 'NNDataPoint_VOIs', ...
    'DP_DICT', dp_list_voi3 ...
    );
%% Create a classifier cross-validation
nn_template = NNClassifierMLP_VOIs('EPOCHS', 50, 'LAYERS', [128 128]);
nncv = NNClassifierMLP_CrossValidation_VOIs('D', {d1, d2},'D_VOIS', {d1_vois, d2_vois}, 'KFOLDS', 5, 'NN_TEMPLATE', nn_template);%d2 healthy, d3 MCI, d1 AD
nncv.get('TRAIN');

%% Evaluate the performance
confusion_matrix_ad = nncv.get('C_MATRIX');
av_auc_ad = nncv.get('AV_AUC');
av_macro_auc_ad = nncv.get('AV_MACRO_AUC');
sensitivity_ad = confusion_matrix_ad(1,1)/ sum(confusion_matrix_ad(:,1));
specificity_ad = confusion_matrix_ad(2,2)/ sum(confusion_matrix_ad(:,2));


%% Create a classifier cross-validation
nn_template = NNClassifierMLP_VOIs('EPOCHS', 50, 'LAYERS', [128 128]);
nncv = NNClassifierMLP_CrossValidation_VOIs('D', {d3, d2},'D_VOIS', {d3_vois, d2_vois}, 'KFOLDS', 5, 'NN_TEMPLATE', nn_template);%d2 healthy, d3 MCI, d1 AD
nncv.get('TRAIN');

%% Evaluate the performance
confusion_matrix_mci = nncv.get('C_MATRIX');
av_auc_mci = nncv.get('AV_AUC');
av_macro_auc_mci = nncv.get('AV_MACRO_AUC');
specificity_mci  = confusion_matrix_mci(1,1)/ sum(confusion_matrix_mci(:,1));
sensitivity_mci = confusion_matrix_mci(2,2)/ sum(confusion_matrix_mci(:,2));



